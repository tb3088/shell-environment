#ref: https://docs.aws.amazon.com/cli/latest/reference/index.html#cli-aws

[ "${0##*/}" != "${BASH_SOURCE##*/}" ] || { >&2 echo "ERROR! file must be sourced"; return 2; }

for exe in curl aws jq log runv; do
  type -p $exe &>/dev/null || { >&2 echo "ERROR! unknown command ($exe)"; return 2; }
done

# all output is in JSON with rare exception
# NOTICE! 'jq -r' returns "null" on empty so either check RC or embed '//empty' into queries
AWS="eval aws --region \${AWS_DEFAULT_REGION:-\$__aws_region} --output json"
JQ='jq --exit-status'; JQR="$JQ --raw-output"

declare -p __aws_session &>/dev/null ||
declare -Ar __aws_session=(
    [AccessKeyId]='aws_access_key_id'
    [SecretAccessKey]='aws_secret_access_key'
    [SessionToken]='aws_session_token'
    [Expiration]='aws_session_expire'
  )

#ref: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html
# aws ec2 describe-regions --query 'Regions[].{ Name:RegionName }' | jq -r '.[].Name'

is_array __aws_regions &>/dev/null && [ ${#__aws_regions[@]} -ge 16 ] ||
declare -ar __aws_regions=(
    ap-northeast-{1,2}
    ap-south-1
    ap-southeast-{1,2}
    ca-central-1
    eu-central-1
    eu-north-1
    eu-west-{1,2,3}
    sa-east-1
    us-east-{1,2}
    us-west-{1,2}
  )

#for region in ${__aws_regions[@]}; do
#  __aws_availability_zones[$region]=`aws ec2 describe-availability-zones \
#      --region $region \
#      --query 'AvailabilityZones[].{ Name:ZoneName }' --output text`
#  #alt: ... | jq --raw-output '.AvailabilityZones[].ZoneName | @sh'`
#done

is_hash __aws_availability_zones &>/dev/null && [ ${#__aws_availability_zones[@]} -ge 16 ] ||
declare -Ar __aws_availability_zones=(
    [ap-northeast-2]=`printf "%s " ap-northeast-2{a,c}`
    [ap-northeast-1]=`printf "%s " ap-northeast-1{a,c,d}`
    [ap-south-1]=`printf "%s " ap-south-1{a..b}`
    [ap-southeast-1]=`printf "%s " ap-southeast-1{a..c}`
    [ap-southeast-2]=`printf "%s " ap-southeast-2{a..c}`
    [ca-central-1]=`printf "%s " ca-central-1{a..b}`
    [eu-central-1]=`printf "%s " eu-central-1{a..c}`
    [eu-north-1]=`printf "%s " eu-north-1{a..c}`
    [eu-west-1]=`printf "%s " eu-west-1{a..c}`
    [eu-west-2]=`printf "%s " eu-west-2{a..c}`
    [eu-west-3]=`printf "%s " eu-west-3{a..c}`
    [sa-east-1]=`printf "%s " sa-east-1{a,c}`
    [us-east-1]=`printf "%s " us-east-1{a..f}`
    [us-east-2]=`printf "%s " us-east-2{a..c}`
    [us-west-1]=`printf "%s " us-west-1{a,c}`
    [us-west-2]=`printf "%s " us-west-2{a..c}`
  )


function ec2.metadata() {
  local url='http://169.254.169.254/latest/meta-data'
  local CURL="curl --connect-timeout 2 ${VERBOSE:+ --verbose --progress-bar} --silent"
  local item mac

  # special cases that require recursion etc.
  case ${item:=$1} in
    vpc|vpc-id)
        : ${mac:=`$FUNCNAME mac`}
        item='vpc-id'
        ;;
    region)
        $FUNCNAME availability-zone | sed 's/[a-z]$//'
        return
        ;;
  esac

  local -A mapping=(
      [az]=placement/availability-zone
      [availability-zone]=placement/availability-zone
      [self]=instance-id
      [type]=instance-type
      [vpc-id]=network/interfaces/macs/$mac/vpc-id
    )

  # intermediary items (eg. macs) leave behind trailing '/'
  ${DEBUG:+ runv} $CURL "$url/${mapping[$item]:-$item}" | sed 's|/$||'
}
#ami-id
#hostname
#instance-id
#instance-type
#local-ipv4
#public-ipv4

# safety fall-back in case AWS_DEFAULT_REGION not set
declare -p __aws_region &>/dev/null || {
    __aws_region=`aws configure get region`
    : ${__aws_region:=`aws configure get region --profile default 2>/dev/null`}
    : ${__aws_region:=`ec2.metadata region`}
    : ${__aws_region:=us-east-1}

    declare -r __aws_region
  }

function is_aws() { ec2.metadata self &>/dev/null; }


function aws.region {
  local region

  if [ -z "$1" ]; then
    echo; printf ' %s\n' ${__aws_regions[@]} | sort | column; echo
    read -t 8 -ep "Choose REGION:  " -i 'us-east-1' || return
    region=$REPLY
  fi

  [ -n "${__aws_availability_zones[$region]}" ] && export AWS_DEFAULT_REGION=$region || log.error "invalid region ($region)"
}


function aws.profile {
  if [ "$1" = 'RESET' ]; then
    aws.rmPath
	unset ${!AWS_*}
    return
  fi

  local profile region config
  : ${profile:=$1}
  : ${region:=$2}
  : ${config:=${AWS_CONFIG_FILE:-"$HOME"/.aws/config}}
  is_file "$config" "$AWS_SHARED_CREDENTIALS_FILE" || return

  if [ -z "$profile" ]; then
    local -a list=( `awk '$1 ~ /^\[profile/ { sub(/]\s*/, "", $2); print $2; }' "$config" | sort` )

    [ ${#list[@]} -ge 1 ] || { log.error "no profiles defined ($config)"; return; }

    [ ${#list[@]} -gt 1 ] && {
        echo; printf ' %s\n' "${list[@]}" | column; echo
        read -t 12 -ep "Choose PROFILE:  " -i "${list[0]}" || return
      }
    profile=$REPLY
  fi

  # BUG! 'aws configure get' does NOT follow 'source_profile' keyword
  # nor fall-thru to 'default' unless profile is unspecified.
  #
  # aws-cli (boto-core?) returns 255 on ProfileNotFound, but will
  # stacktrace on empty values of AWS_PROFILE.
  #
  # BUG! 'aws configure' emits to STDERR instead of STDOUT
  local _region=`aws configure get region ${profile:+ --profile "$profile"} 2>&1 | tail -n 1`
  if [[ $? -eq 255 || "$_region" =~ ProfileNotFound ]]; then
    RC=1 log.error "$_region ($config)"
    return
  fi
  : ${region:=$_region}

  # possible short-circuit
  [ "$profile" = "$AWS_PROFILE" -a "${region:-$AWS_DEFAULT_REGION}" = "${AWS_DEFAULT_REGION:-unset}" ] && return

  ${DEBUG:+ runv} aws.rmPath    # cleanup previous environment

  AWS_PROFILE=$profile
  aws.region "$region" || return

  unset AWS_{,SECRET_}ACCESS_KEY{_ID,} AWS_SESSION_{TOKEN,EXPIRE}
  ${DEBUG:+ runv} aws.addPath
  if [ -n "$AWS_CONFIG_FILE" ]; then
    local _creds=${AWS_CONFIG_FILE%/*}/credentials
    [ -f "$_creds" ] &&
        : ${AWS_SHARED_CREDENTIALS_FILE:=$_creds}
  fi

  export ${!AWS_*}
}


function aws.printenv() {
  local v
  for v in ${!AWS_*}; do echo "$v=${!v}"; done
}


function aws.session-load {
  local format='text'
  local input=$1
  local cache_dir="$HOME"/.aws/cli/cache

  if [ -z "$input" ]; then
    local -a list=( `cd "$cache_dir" 2>/dev/null && find . -type f -mmin -$((${AWS_SESSION_DURATION:-3600} / 60))` )

    [ ${#list[@]} -ge 1 ] || { log.error "no cached sessions ($cache_dir)"; return; }

    [ ${#list[@]} -gt 1 ] && {
        echo; printf ' %s\n' "${list[@]}" | column; echo
        read -t 12 -ep "Choose cached SESSION:  " -i "${list[0]}" || return
      }
    input=$cache_dir/$REPLY
  fi

  [ -f "$input" ] && { input=$( <"$input" ) || return; }
  jq . <<< "$input" &>/dev/null && format='json'

  case "$format" in
    text)   # see 'aws.session()' call to 'aws sts'
            local header rest
            log.debug "$input"
#FIXME something very wrong in 'text' mode
log.error "code is broken ($FUNCNAME)"; return
#            IFS=$'\t' read -r header AWS_ACCESS_KEY_ID AWS_SESSION_EXPIRE \
#                AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN rest <<< "$input"
            ;;
    json)   local field; local -u envvar
            log.debug `jq -MS '.Credentials' <<< "$input"`
            for field in `keys __aws_session`; do
              envvar=`value __aws_session $field`
              local -n nref=$envvar
              nref=`$JQR --arg field "$field" '.Credentials[$field]' <<< "$input"`
            done
            log.info `$JQR '.AssumedRoleUser' <<< "$input"`
            ;;
    *)      RC=2 log.error "unsupported format ($format)"
            return
  esac
  log.info `aws.printenv`
  export ${!AWS_*}
}


function aws.session-write {
    local field; local -u envvar

    for field in `keys __aws_session`; do
      envvar=`value __aws_session $field`
      ${DEBUG:+ runv} aws configure set "${envvar,,}" "${!envvar}"
    done
}


function aws.session {
  # https://docs.aws.amazon.com/STS/latest/APIReference/API_GetSessionToken.html
  #NOTE AWS CLI will NOT let you 'get-session-token' if there is a 'role_arn' defined!

  local -ir now=`date '+%s'`
  local -i duration write=0 force=0
  # Bash 'integer' doesn't handle leading ZEROs
  local cmd cache output role profile token mfa

  local OPTIND opt
  while getopts ':cfp:r:T:t:W' opt; do
    case "$opt" in
      c)    for f in "$HOME"/.aws/cli/cache/*; do
              [ -f "$f" ] || continue
              expires=$(date --date `$JQR '.Credentials.Expiration' "$f"` '+%s')
              [ $now -lt ${expires:-0} ] || { rm -f "$f"; continue; }

              #FIXME first valid != desired AWS_PROFILE, is $profile set?
              cache=$f
              break
            done
            ;;
      f)    force=1 ;;
      p)    profile=$OPTARG ;;
      r)    role=$OPTARG ;;
      T)    duration=$OPTARG ;;
      t)    [[ $OPTARG =~ [0-9]{6} ]] && token=$OPTARG || { log.error "invalid Token ($OPTARG)"; return; }
            ;;
      W)    # save session to AWS_SHARED_CREDENTIALS_FILE (potentially DANGEROUS!)
            write=1
            ;;
      :)    RC=2 log.error "missing argument (-$OPTARG)"; return ;;
      \?)   log.error "invalid option (-$OPTARG)" ;&
      h)    >&2 echo "Usage: $FUNCNAME ... TODO"
            return 2
    esac
  done
  shift $((OPTIND-1))

  #BUG! STS service rejects duration > 3600 despite documentation
  [ ${duration:-0} -gt 3600 ] && unset duration

  while [ "${1+x}" ]; do
    if [[ $1 =~ [0-9]{6} ]]; then
      token=$1
    elif [[ $1 =~ ^arn:aws:iam: ]]; then
      role=$1
    elif [[ $1 =~ ^[a-zA-Z]+ ]]; then
      profile=$1
    else
      log.warn "unknown format ($1)"
      break
    fi
    shift
  done

  aws.profile "${profile:-$AWS_PROFILE}" || return

#  mfa=`aws configure get mfa_serial`
#  if [[ $? -eq 255 || "$mfa" =~ ProfileNotFound ]]; then
#    # not reached, aws.profile() should have caught it
#    RC=1 log.critical "unknown profile ($profile, $AWS_CONFIG_FILE)"
#    return
#  fi

  : ${role:=`aws configure get role_arn 2>/dev/null`}

  if [ -n "$role" ]; then
    # 'role-session-name' pattern is [\w+=,.@-]* and 45 char limit
    local session_name="${role#*:role/}"
    local session_suffix="${AWS_PROFILE}.$$"
    session_name="${session_name:0:$((44-${#session_suffix}))}@${session_suffix}"
    session_name="${session_name//:/.}"
    cmd=( "assume-role" "--role-arn=$role" "--role-session-name=$session_name" )
  else
    cmd='get-session-token'
  fi

  if [ -z "$cache" -o $force -eq 1 ]; then
    unset cache
    output=$(
        local field
        local -u key

# FIXME use same pattern as aws.session-load with 'keys' and 'values'
        for field in "${!__aws_session[@]}"; do
          key="${__aws_session[$field]}"
          unset $key
        done

        ${DEBUG:+ runv} aws sts ${DEBUG:+ --debug} "${cmd[@]}" \
            ${mfa:+ --serial-number="$mfa" ${token:+ --token-code=$token}} \
            ${duration:+ --duration-seconds=$duration} \
            --output json
    ) || return
#FIXME BotoCore has a bug (tries a second OP) that throws 255 despite first OP yields success
#An error occurred (AccessDenied) when calling the AssumeRole operation: MultiFactorAuthentication failed, must provide both MFA serial number and one time pass code.
# if the token is wrong you get:
#An error occurred (AccessDenied) when calling the AssumeRole operation: MultiFactorAuthentication failed with invalid MFA one time pass code.
  fi

  aws.session-load "${cache:-$output}" || return
  [ $write -eq 1 ] && aws.session-write

  log.info `aws.printenv`
  export ${!AWS_*}
}


function aws.addPath {
  local v f
  local -i delete

  for v in "$@" \
        ${AWS_CONFIG_FILE:+`eval echo $(dirname "$AWS_CONFIG_FILE")${AWS_PROFILE:+"{/$AWS_PROFILE,}"}`} \
        ${AWS_PROFILE:+`echo "$HOME"/.{aws,ssh}/$AWS_PROFILE`}; do
    [ -n "$v" ] || continue
    [ "$v" = '.' ] && v=`pwd`

    for f in "$v"/bin; do
      if [ ${delete:-0} -eq 1 ]; then
        ${DEBUG:+ runv} rmPath "$f"
      else
        [ -d "$f" ] || continue
        ${DEBUG:+ runv} addPath -"$f"
      fi
    done

    [ -n "$SSH_AUTH_SOCK" ] &&
      for f in `eval echo "$v"/${AWS_DEFAULT_REGION:+"{$AWS_DEFAULT_REGION/,}"}{id_*,*.pem,*.pub}`; do
        [ -f "$f" ] || continue
        ${DEBUG:+ runv} ssh-add ${delete:+ -d} "$f" &>/dev/null
      done
  done
}


function aws.rmPath {
  delete=1 aws.addPath "$@"
}


function aws.route53-export {
  local -u zone_id=${1:?zone_id}
  local domain=${1%.}; domain+='.'

  # if doesn't match pattern assume Domain name was specified
  #FIXME will pick first occurance which is likely not intended, use read() to prompt
  grep -qE '([A-Z]|[0-9]){12,}' <<< "$zone_id" || zone_id=$(
      aws route53 list-hosted-zones --output=json |
      $JQR --arg domain "$domain" '.HostedZones[] | select(.Name == $domain) | .Id' |
      cut -d'/' -f3 | head -n 1
    )

  for zone in $zone_id; do
    echo -e "; $zone\n"
    #TODO use printf() with width
    aws route53 list-resource-record-sets --hosted-zone-id=${zone:?} --output=json |
        jq -jr '.ResourceRecordSets[] | "\(.Name)\t\(.TTL)\t\(.Type)\t\(.ResourceRecords[].Value)\n"'
    echo
  done
}


function aws.sshkeys {
  # Example: $FUNCNAME `$AWS iam get-group --group-name <group> | $JQR '.Users[].UserName'`
  local -u format
  local status

  : ${format:=ssh}
  : ${status:=Active}

  while [ "$1" ];do
    for kid in $( $AWS iam list-ssh-public-keys --user-name "$1" |
        $JQR --arg STATUS "$status" '.SSHPublicKeys[] | select( .Status == $STATUS) | .SSHPublicKeyId //empty' )
    do
      $AWS iam get-ssh-public-key --user-name "$1" --ssh-public-key-id "$kid" --encoding $format |
          $JQR '.SSHPublicKey | .UserName, .SSHPublicKeyBody | @sh'
    done
    shift
  done
}


# function aws-kms-crypt (de/en) are simple 1 liner calls to kms-crypt
# -e for encrypt, -d for decrypt. -B to pipe results to base64 -d. must NOT decode (ie. consume the already base64-encoded
# cyphertext as-is for assignment to Bash variables. Pipes, however have no such limitation.
# shamelessly cribbed from https://stackoverflow.com/questions/49537224/how-can-i-call-amazons-aws-kms-decrypt-function-without-using-a-binary-file/53735748#53735748
# remember to whack Gruntwork's retarded 'kmscrypt::' header both forward and backward.
#
# also support -j and auto-detect on 1st char = '{'
# aws kms  decrypt --ciphertext-blob fileb://<(sed -e 's/^kmscrypt:://' post | base64 -d) --query Plaintext --output text
# }


function aws.describe() {
  local type output arn
  local -a filter

  resource=${1:?resource}; shift

  case $resource in
#    asg|autoscaling-group)
    s3|*bucket)
            ${DEBUG:+ runv} $AWS s3api list-buckets $JQ --arg bucket "${1:?bucket}" '.Buckets[] | select(.Name == $bucket)' ;;
    *bucket-policy)
            # last JQ used to un-escape embedded stanza
            ${DEBUG:+ runv} $AWS s3api get-bucket-policy --bucket "${1:?bucket}" | $JQR '.Policy' | $JQ '.' ;;

#    ec2|*instance)
#    elastic-ip)
#    internet-gateway
#    nat-gateway
    tag)    filter+=( "Name=key,Values=${2:?key}" )
            ;&
    tags)   filter+=(
                "Name=resource-type,Values=${type:-instance}"
                "Name=resource-id,Values=${1:?resource-id}"
              )
            output=`$AWS ec2 describe-tags --filters "${filter[@]}"`
            ;;&

            # NOTE! 'tag' emits text
    tag)    ${DEBUG:+ runv} $JQR '.Tags[0].Value' <<< "$output" ;;
    tags)   ${DEBUG:+ runv} $JQ '.Tags[] | {(.Key): .Value}' <<< "$output" | $JQ -s add ;;
#    route)
#    subnet)
    target-group)
            ${DEBUG:+ runv} $AWS elbv2 describe-target-groups |
                $JQ --arg tg ${1:?target_group_name} '.TargetGroups[] | select(.TargetGroupName == $tg)'
            ;;

#   ebs|volume) describe-volume
    volume-attachment)
            ${DEBUG:+ runv} $AWS ec2 describe-volumes --volume-ids ${1:?volume_id} |
                $JQ '.Volumes[].Attachments[0]'
            ;;
    volume-status) # ok, creating, ?
            ${DEBUG:+ runv} $AWS ec2 describe-volume-status --volume-ids ${1:?volume_id} |
                $JQR '.VolumeStatuses[].VolumeStatus.Status //empty'
            ;;
    vpc)    ${DEBUG:+ runv} $AWS ec2 describe-vpcs --vpc-id ${1:?vpc_id} | $JQ '.Vpcs[]' ;;
#    vpc-endpoint
#        describe-vpc-endpoint-services
#        describe-vpc-endpoints
#    target-group)
#    elb|lb|load-blancer)
#    security-group)
#   launch-config)

    *)      >&2 echo "unsupported keyword"; return 2
  esac
}


function asg.suspend() {
  asg=${1:?ASG name}; shift
  aws autoscaling enter-standby --should-decrement-desired-capacity --auto-scaling-group-name "$asg" ${1:+ --instance-ids "$@"}
}


function asg.resume() {
  asg=${1:?ASG name}; shift
  aws autoscaling exit-standby --auto-scaling-group-name "$asg" ${1:+ --instance-ids "$@"}
}


function asg.scale-zero() {
  min=0 desired=0 asg.capacity "$@"
}


function asg.set-capacity() {
  [ "${min}${desired}${max}" ] || return 2

  aws autoscaling update-auto-scaling-group \
      ${min:+ --min-size $min} ${desired:+ --desired-capacity $desired} ${max:+ --max-size $max} \
	  --auto-scaling-group-name "${1:?ASG name}"
}


#function aws.ssh takes after 18f script that probes for region, VPC, and then instance

#function s3.restore
#aws s3 ls s3://<bucket_name> | awk '{print $4}' | xargs -L 1 aws s3api restore-object --restore-request Days=<days> --bucket <bucket_name> --key
# or better
# s3cmd restore --recursive s3://mybucketname/ 


# vim: expandtab:ts=4:sw=2
