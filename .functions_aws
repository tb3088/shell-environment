#----- header -----
[ "${0##*/}" != "${BASH_SOURCE##*/}" ] || { >&2 echo -e "ERROR\tfile must be sourced ($0)"; return 2; }
#------------------

shopt -s extglob

#ref: https://docs.aws.amazon.com/cli/latest/reference/index.html#cli-aws

is_exec jq curl || { >&2 echo -e "ERROR\tmissing tools (jq, curl)"; exit 2; }
__aws_bin=`VERBOSE=1 is_exec "aws${AWS_VERSION}"` || exit 2

is_function __AWS ||
function __AWS {
  local -a cmd=()

  # windows binary can't walk symlinks or handle unix'y paths
  if is_windows "$__aws_bin"; then
    [ -n "$AWS_CONFIG_FILE" ] &&
        cmd+=( AWS_CONFIG_FILE=`convert_path -w "$AWS_CONFIG_FILE"` )

    [ -n "$AWS_SHARED_CREDENTIALS_FILE" ] &&
        cmd+=( AWS_SHARED_CREDENTIALS_FILE=`convert_path -w "$AWS_SHARED_CREDENTIALS_FILE"` )

    [[ "$cmd" =~ AWS_ ]] && cmd=( env "${cmd[@]}" )
  fi

  cmd+=( "${__aws_bin:?}" '--output' json )

  # NOTE - EC2 instances may lack AWS config
  # interactive use assumes correctness or may blow up
  if [ -z "${AWS_DEFAULT_REGION}" ]; then
    local region=`is_ec2 && ec2.metadata region || "${cmd[@]}" configure get region`
    cmd+=( '--region' "${region:?}" )
  fi

  [ "${DEBUG:-0}" -gt 1 -o -n "$TRACE" ] && cmd+=( '--debug' )

  # all output is in JSON with rare exception
  ${DEBUG:+ runv} "${cmd[@]}" "$@"
}
readonly -f __AWS

is_function __JQ ||
function __JQ { ${DEBUG:+ runv} jq --exit-status "$@"; }
readonly -f __JQ

# NOTICE! 'jq -r' returns literal "null" on empty, so either check RC or embed '//empty' into queries
is_function __JQR ||
#function __JQR { ${DEBUG:+ runv} jq --exit-status --raw-output "$@"; }
function __JQR { __JQ "$@" | jq --raw-output '. // empty'; }
readonly -f __JQR

is_function __CURL ||
function __CURL { ${DEBUG:+ runv} curl --connect-timeout 5 --fail --silent \
       ${VERBOSE:+ --verbose --progress-bar} "$@"; }
readonly -f __CURL

# CLI safety fall-back in case neither AWS_DEFAULT_REGION or configuration defaults
is_hash __aws_defaults ||
declare -Ar __aws_defaults=(
    [region]='us-east-1'
    [config]="$HOME/.aws/config"
    [credentials]="$HOME/.aws/credentials"
  )

is_hash __aws_session ||
declare -Ar __aws_session=(
    [AccessKeyId]='aws_access_key_id'
    [SecretAccessKey]='aws_secret_access_key'
    [SessionToken]='aws_session_token'
    [Expiration]='aws_session_expire'
  )

is_hash __aws_regex ||
declare -Ar __aws_regex=(
    [token]='^[0-9]{6}'
    [role]='^arn:aws:iam:'
    [region]='^[a-z]{2}-[a-z]+-[0-9]'
    [profile]='^[a-zA-Z]+'
  )

#ref: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html
# aws ec2 describe-regions | JQR '.Regions[].RegionName | sort'
is_array __aws_regions && [ ${#__aws_regions[@]} -ge 16 ] ||
declare -ar __aws_regions=(
    ap-northeast-{1,2}
    ap-south-1
    ap-southeast-{1,2}
    ca-central-1
    eu-central-1
    eu-north-1
    eu-west-{1,2,3}
    sa-east-1
    us-east-{1,2}
    us-west-{1,2}
  )

#for region in ${__aws_regions[@]}; do
#  __aws_availability_zones[$region]=`aws ec2 describe-availability-zones \
#      --region $region \
#      --query 'AvailabilityZones[].{ Name:ZoneName }' --output text`
#  #alt: ... | JQR '.AvailabilityZones[].ZoneName | @sh'`
#done

is_hash __aws_availability_zones && [ ${#__aws_availability_zones[@]} -ge 16 ] ||
declare -Ar __aws_availability_zones=(
    [ap-northeast-1]=$(echo ap-northeast-1{a,c,d})
    [ap-northeast-2]=$(echo ap-northeast-2{a,c})
    [ap-south-1]=$(echo ap-south-1{a..b})
    [ap-southeast-1]=$(echo ap-southeast-1{a..c})
    [ap-southeast-2]=$(echo ap-southeast-2{a..c})
    [ca-central-1]=$(echo ca-central-1{a..b})
    [eu-central-1]=$(echo eu-central-1{a..c})
    [eu-north-1]=$(echo eu-north-1{a..c})
    [eu-west-1]=$(echo eu-west-1{a..c})
    [eu-west-2]=$(echo eu-west-2{a..c})
    [eu-west-3]=$(echo eu-west-3{a..c})
    [sa-east-1]=$(echo sa-east-1{a,c})
    [us-east-1]=$(echo us-east-1{a..f})
    [us-east-2]=$(echo us-east-2{a..c})
    [us-west-1]=$(echo us-west-1{a,c})
    [us-west-2]=$(echo us-west-2{a..c})
  )


# approximate clone of program from ec2-utils.rpm
function ec2.metadata() {
  local url='http://169.254.169.254/latest/meta-data'
  local item mac
  local -A mapping=(
      [a]='ami-id'
      [b]='block-device-mapping/'
      [availability-zone]='placement/availability-zone'
      [e]='reservation-id'
      [h]='local-hostname'
      [i]='instance-id'
      [l]='ami-launch-index'
      [m]='ami-manifest-path'
      [o]='local-ipv4'
      [p]='public-hostname'
      [s]='security-groups'
      [t]='instance-type'
      [u]='public-keys'
      [v]='public-ipv4'
    )

  : ${item:=$(echo "$1" | sed -E 's/^-+//')}

  # special/custom cases
  case "$item" in
#-c/--product-codes        Product codes associated with this instance.
#-d/--user-data            User-supplied data.Only available if supplied at instance launch time.
    self)   item='i' ;;
#-k/--kernel-id            The ID of the kernel launched with this instance, if applicable.
#-n/--ancestor-ami-ids     The AMI IDs of any instances that were rebundled to create this AMI.
#-r/--ramdisk-id           The ID of the RAM disk launched with this instance, if applicable.
    _public-keys*)
            item="${item#_}" ;;
    public-keys)
            while read line; do
#              echo "$line"
              while read format; do
                # convert multi-line to single
                $FUNCNAME "_$item/${line%%=*}/$format" | sed ':a;N;s/\n//;ta'
              done < <( $FUNCNAME "_$item/${line%%=*}" )
#              echo  #----------
            done < <( $FUNCNAME "_$item" )
            #TODO selective print by index or by key name
            return
            ;;
    region) $FUNCNAME 'availability-zone' | sed 's/[a-z]$//'; return
            ;;
    subnet?(-id))
            item="network/interfaces/macs/$($FUNCNAME mac)/subnet-id"
            ;;
    type)   item='t' ;;
    vpc?(-id))
            item="network/interfaces/macs/$($FUNCNAME mac)/vpc-id"
            ;;
    z|az)   item='availability-zone' ;;

# Interferes with fall-through
#    *)  [ -n "${mapping[$item]}" ] ||
#            log.error "unsupported format ($format)"; return 2
  esac

  # intermediary items (eg. MACs) leave behind trailing '/'
  __CURL "$url/${mapping[$item]:-$item}" | sed 's|/$||'
}


function is_ec2 { ec2.metadata self &>/dev/null; }


function aws.region {
  # 'default' supplied by `aws configure` in aws.profile()
  local default
  local region=${1-'prompt'}
  shift

  # '' (empty string) avoids prompt provided AWS_DEFAULT_REGION is set,
  # or can fall-back on configuration default
  [ -z "$region" -a -n "${AWS_DEFAULT_REGION:-$default}" ] && return

  if [ "$region" = 'prompt' ]; then
    echo
    keys=1 array.print __aws_regions | column
    echo
    read -t 15 -ep "Choose REGION:  " -i "${AWS_DEFAULT_REGION:-$__aws_regions}" || return

    [[ "{$REPLY:0:1}" =~ [0-9] ]] && region=${__aws_regions[$REPLY]} || region=$REPLY
  fi

  # validity check
  [ -n "${__aws_availability_zones[$region]}" ] || {
      log.error "invalid region ($region)"; return
    }

  export AWS_DEFAULT_REGION=$region
}


function aws.profile {
  [ "${1^^}" = 'RESET' ] && { aws.rmPath; unset ${!AWS_*}; return; }

  # '' (empty string) avoids prompt, assumes $AWS_PROFILE or 'default'
  local profile
  : ${profile=${1-'prompt'}}
  shift

  # but force the issue if called from aws.session()
  [ "${FUNCNAME[1]}" = 'aws.session' ] && {
      [ -n "$profile" ] || profile='prompt'
    }

  local config creds
  if [ -n "$AWS_CONFIG_FILE" ]; then
    config=`$READLINK -ve "$AWS_CONFIG_FILE"` || return
    [ -n "$AWS_SHARED_CREDENTIALS_FILE" ] && {
        creds=`$READLINK -ve "$AWS_SHARED_CREDENTIALS_FILE"` || return
      }
  else
    unset AWS_CONFIG_FILE AWS_SHARED_CREDENTIALS_FILE
    config=`$READLINK -ve "${__aws_defaults[config]}"` || return
    creds=`$READLINK -ve "${__aws_defaults[credentials]}"` || return
  fi

  if [ "${config%/*}" != "${creds%/*}" ]; then
    AWS_SHARED_CREDENTIALS_FILE=${AWS_CONFIG_FILE%/*}/credentials
    log.notice "overriding CREDENTIALS_FILE (${creds:-unset} -> $AWS_SHARED_CREDENTIALS_FILE)"
    creds=`$READLINK -ve "$AWS_SHARED_CREDENTIALS_FILE"` || return
  fi

  if [ "$profile" = 'prompt' ]; then
    local pattern='$1 ~ /^\[\w+/ { gsub(/\[|\]/, "", $NF); print $NF; }'
    local -a list=(
        $(awk -- "$pattern" "$config")
        $(awk -- "$pattern" "$creds")
      )
    # sanitize
    list=( $(IFS=$'\n'; sort -u <<< "${list[*]}") )

    if [ ${#list[@]} -ge 1 ]; then
      echo
      keys=1 array.print list | column
      echo
      read -t 15 -ep "Choose PROFILE:  " -i "$list" || return

      [[ "${REPLY:0:1}" =~ [0-9] ]] && profile=${list[$REPLY]} || profile=$REPLY
    else
      log.error "No profiles found ($config, $creds)"
      return
    fi
  fi

  [ "$profile" = 'default' ] && unset profile

    # BUG! 'aws configure get' does NOT follow 'source_profile' keyword
    # nor fall-thru to 'default' if --profile is specified.
    #
    # aws-cli (boto-core) returns 255 on ProfileNotFound, but will also
    # stacktrace if value of AWS_PROFILE is not defined in file(s).
    #
    # $? == 1 simply means no explicit declaration
    local _region=$( __AWS --output text configure get region
        ${profile:+ --profile "$profile"} 2>/dev/null | tr -d $'\r' )

    [[ $? -eq 255 || "${_region:-unset}" =~ ProfileNotFound ]] && {
        log.error "undefined profile ($profile)"
        return 255
      }

  if [ "${profile:-A}" != "${AWS_PROFILE:-B}" ]; then
    # cleanup previous environment
    aws.rmPath
    unset AWS_{,SECRET_}ACCESS_KEY{_ID,} AWS_SESSION_{TOKEN,EXPIRE}
  fi

  [ -n "$profile" ] && AWS_PROFILE="$profile" || unset AWS_PROFILE
  default="$_region" aws.region "$@" || return

  aws.addPath
  export ${!AWS_*}
}


function aws.printenv {
  local v
  for v in ${!AWS_*}; do echo "$v=${!v}"; done
}


function aws.session-load {
  local format='text'
  local input=$1
  local cache_dir="$HOME"/.aws/cli/cache

  if [ -z "$input" ]; then
    local -a list=( $( cd "$cache_dir" 2>/dev/null &&
       find . -type f -mmin -$((${AWS_SESSION_DURATION:-3600} / 60)) )
     )

    [ ${#list[@]} -ge 1 ] || { log.warn "no cached sessions ($cache_dir)"; return; }

    echo
    keys=1 array.print list | column
    echo
    read -t 12 -ep "Choose cached SESSION:  " -i "$list" || return

    [[ "${REPLY:0:1}" =~ [0-9] ]] && input="$cache_dir/${list[$REPLY]}" || input="$cache_dir/$REPLY"
  fi

  # read file into variable
  [ -f "$input" ] && input=$( <"$input" )

  __JQ . <<< "$input" &>/dev/null && format='json'

  case "$format" in
    text)   # see 'aws.session()' call to 'aws sts'
            local header rest
            log.debug "$input"
#FIXME something very wrong in 'text' mode
log.error "code is broken ($FUNCNAME, $format)"; return 128
#            IFS=$'\t' read -r header AWS_ACCESS_KEY_ID AWS_SESSION_EXPIRE \
#                AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN rest <<< "$input"
            ;;

    json)   local field; local -u envvar
            __JQ -MS '.Credentials' <<< "$input" | log.debug
            for field in $(keys __aws_session); do
              envvar=$(value __aws_session $field)
              local -n nref=$envvar
              nref=$( __JQR --arg field "$field" '.Credentials[$field]' <<< "$input" )
            done
            __JQR '.AssumedRoleUser' <<< "$input" | log.info
            ;;

    *)      log.error "unsupported format ($format)"; return 2
  esac

  aws.printenv | log.info
  export ${!AWS_*}
}


function aws.session-write {
    local field; local -u envvar

    for field in $(keys __aws_session); do
      envvar=$(value __aws_session "$field")
      ${DEBUG:+ runv} __AWS configure set "${envvar,,}" "${!envvar}"
    done
}


function aws.session {
  # https://docs.aws.amazon.com/STS/latest/APIReference/API_GetSessionToken.html
  #NOTE AWS CLI will NOT let you 'get-session-token' if there is a 'role_arn' defined!

  local -ir now=$(date '+%s')
  local -i duration write=0 force=0
  # Bash 'integer' doesn't handle leading ZEROs
  local cache output role profile token mfa

  local OPTIND opt
  while getopts ':cfp:r:T:t:W' opt; do
    case "$opt" in
      c)    for f in "$HOME"/.aws/cli/cache/*; do
              [ -f "$f" ] || continue

              expires=$(date --date `__JQR '.Credentials.Expiration' "$f"` '+%s')
              [ ${expires:-0} -ge ${now:-0} ] || { rm -f "$f"; continue; }

              #FIXME first valid != desired AWS_PROFILE, is $profile set?
              cache=$f
              break
            done
            ;;
      f)    force=1 ;;
      p)    profile=$OPTARG ;;
      R)    role=$OPTARG ;;
      r)    region=$OPTARG ;;
      T)    duration=$OPTARG ;;
      t)    [[ "$OPTARG" =~ [0-9]{6} ]] && token=$OPTARG || {
                log.error "invalid Token ($OPTARG)"
                return
              }
            ;;
      # save session to AWS_SHARED_CREDENTIALS_FILE (potentially DANGEROUS!)
      W)    write=1 ;;
      :)    log.error "missing argument (-$OPTARG)"; return 2 ;;
      \?)   log.error "unsupported (-$OPTARG)" ;&
      h|*)  >&2 echo "Usage: $FUNCNAME ... TODO"
            return 2
    esac
  done
  shift $((OPTIND - 1))

  #BUG! STS service rejects duration > 3600 despite documentation
  [ ${duration:-0} -gt 3600 ] && unset duration

  #WARN unsafe backwards compat
  while [ "${1+x}" ]; do
    if [[ $1 =~ ${__aws_regex[token]} ]]; then
      token=$1
    elif [[ $1 =~ ${__aws_regex[role]} ]]; then
      role=$1
    elif [[ ${1,,} =~ ${__aws_regex[region]} ]]; then
      region=$1
    elif [[ $1 =~ ${__aws_regex[profile]} ]]; then
      profile=$1
    else
      log.error "unknown format ($1)"
      return
    fi
    shift
  done

  aws.profile "${profile:-$AWS_PROFILE}" "${region:-$AWS_DEFAULT_REGION}" || return
  : ${role:=`__AWS configure get role_arn | tr -d $'\r'`}

  local cmd=()

  if [ -n "$role" ]; then
    # 'role-session-name' pattern is [\w+=,.@-]* and 45 char limit
    local session_name="${role#*:role/}"
    local session_suffix="${AWS_PROFILE:?}.$$"
    session_name="${session_name:0:$((44-${#session_suffix}))}@${session_suffix}"
    session_name="${session_name//:/.}"
    cmd=( 'assume-role' '--role-arn' "$role" '--role-session-name' "$session_name" )
  else
    cmd='get-session-token'
  fi

  if [ -z "$cache" -o ${force:-0} -eq 1 ]; then
    unset cache
    output=$(
        local field
        local -u key

# FIXME use same pattern as aws.session-load with 'keys' and 'values'
        for field in "${!__aws_session[@]}"; do
          key="${__aws_session[$field]}"
          unset $key
        done

        ${DEBUG:+ runv} __AWS sts "${cmd[@]}" \
            ${mfa:+ --serial-number "$mfa" \
            ${token:+ --token-code $token}} \
            ${duration:+ --duration-seconds $duration}
      ) || return
#FIXME BotoCore has a bug (tries a second OP) that throws 255 despite first OP yields success
#An error occurred (AccessDenied) when calling the AssumeRole operation: MultiFactorAuthentication failed, must provide both MFA serial number and one time pass code.
# if the token is wrong you get:
#An error occurred (AccessDenied) when calling the AssumeRole operation: MultiFactorAuthentication failed with invalid MFA one time pass code.
  fi

  aws.session-load "${cache:-$output}" || return
  [ ${write:-0} -eq 1 ] && aws.session-write

  log.info `aws.printenv`
  export ${!AWS_*}
}


#TODO? call recursively
function aws.addPath {
  local -i DELETE
  local -a dirs
  [ -n "$AWS_CONFIG_FILE" ] &&
      dirs+=( "${AWS_CONFIG_FILE%/*}"/**/bin )
  # sanitize
  dirs=( `IFS=$'\n'; sort -u <<< "${dirs[*]}"` )

  for v in "${dirs[@]}"; do
    [ -d "$v" ] || continue

    if [ ${DELETE:-0} -eq 1 ]; then
      ${DEBUG:+ runv} ssh-add ${VERBOSE:+ -v} -d "${v%/bin}"/{id_*,*.pem}.pub &>/dev/null
      rmPath "$v"
    else
# WARN! use 'IdentitiesOnly yes' in ssh_config or else you may
# experience Auth Failure by virtue of too many attempts
      [ ${LOAD_SSHKEYS:-0} -eq 1 ] &&
          ${DEBUG:+ runv} ssh-add ${VERBOSE:+ -v} "${v%/bin}"/{id_*,*.pem}
      prepend=1 addPath "$v"
    fi
  done
}

function aws.rmPath {
  DELETE=1 aws.addPath "$@"
}


function aws.route53-export {
  local -u zone_id=${1:?zone_id}
  local domain=${1%.}; domain+='.'

  # if doesn't match pattern assume Domain name was specified
  #FIXME will pick first occurance which is likely not intended, use read() to prompt
  grep -qE '([A-Z]|[0-9]){12,}' <<< "$zone_id" || zone_id=$(
      __AWS route53 list-hosted-zones |
          __JQR --arg domain "$domain" '.HostedZones[] | select(.Name == $domain) | .Id' |
          cut -d'/' -f3 | head -n 1
    )

  for zone in $zone_id; do
    echo -e "; $zone\n"
    #TODO use printf() with width
    __AWS route53 list-resource-record-sets --hosted-zone-id=${zone:?} |
        __JQR -j '.ResourceRecordSets[] | "\(.Name)\t\(.TTL)\t\(.Type)\t\(.ResourceRecords[].Value)\n"'
    echo
  done
}


#TODO rewrite as aws.describe() item
function iam.sshkeys {
  # Example: $FUNCNAME `__AWS iam get-group --group-name <group> | JQR '.Users[].UserName'`
  local -u format
  local status

  : ${format:=ssh}
  : ${status:=Active}

  while (( $# ));do
    [ "$1" ] || { shift; continue; }

    for kid in $( __AWS iam list-ssh-public-keys --user-name "$1" |
        __JQR --arg STATUS "$status" '.SSHPublicKeys[] | select(.Status == $STATUS) | .SSHPublicKeyId //empty'
      ); do
#TODO use JQ and drop @sh?
      __AWS iam get-ssh-public-key --user-name "$1" --ssh-public-key-id "$kid" --encoding $format |
          __JQR '.SSHPublicKey | .UserName, .SSHPublicKeyBody | @sh'
    done
    shift
  done
}


# function aws-kms-crypt (de/en) are simple 1 liner calls to kms-crypt
# -e for encrypt, -d for decrypt. -B to pipe results to base64 -d. must NOT decode (ie. consume the already base64-encoded
# cyphertext as-is for assignment to Bash variables. Pipes, however have no such limitation.
# shamelessly cribbed from https://stackoverflow.com/questions/49537224/how-can-i-call-amazons-aws-kms-decrypt-function-without-using-a-binary-file/53735748#53735748
# remember to whack Gruntwork's retarded 'kmscrypt::' header both forward and backward.
#
# also support -j and auto-detect on 1st char = '{'
# aws kms  decrypt --ciphertext-blob fileb://<(sed -e 's/^kmscrypt:://' post | base64 -d) --query Plaintext --output text
# }

#TODO? break out into 'ec2.describe', 'iam.describe' 'ssm.get'
#TODO? assume plural and rewrite

function aws.describe() {
  #WARN !! plural supported but beware side-effects !!
  local type= field= resource
  local -a filter=() cmd=() post=()

  [ -n "$resource" ] || { resource=${1:?resource}; shift; }

#TODO getopts() and support output as json, array or Hash
#FIXME rewrite all to use --filter syntax and generic ending below

  case "$resource" in
#    asg|autoscaling-group)

#    iam.user)
#    iam.group?)
#    iam.policy)
    iam.role)
            __AWS iam get-role --role-name "${1:?role}" | __JQ '.Role'
            ;;
    s3|*bucket)
            __AWS s3api list-buckets | __JQ --arg bucket "${1:?bucket}" '.Buckets[] | select(.Name == $bucket)'
            ;;
    *bucket-policy)
            # last JQ used to un-escape embedded stanza (was: | __JQ .)
            __AWS s3api get-bucket-policy --bucket "${1:?bucket}" | __JQ '.Policy | from_json'
            ;;

#    ec2|*instance)
#    instance-role)
#    elastic-ip)
#    internet-gateway
#    nat-gateway

    # https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-tags.html
    ec2.tag?(s)) type='instance'
            ;;&
    eip.tag?(s)) type='elastic-ip'
            ;;&
    tag?(s)|*.tag?(s))
            #TODO non-EC2 items, but do we really need?
            # sqs: list-queue-tags
            # dynamodb: list-tags-of-resource
            #
            # ec2: customer-gateway | dedicated-host | dhcp-options | elastic-ip | fleet
            #      fpga-image | host-reservation | image | instance | internet-gateway
            #      key-pair | launch-template | natgateway | network-acl | network-interface
            #      placement-group | reserved-instances | route-table | security-group
            #      snapshot | spot-instances-request | subnet | volume | vpc | vpc-endpoint
            #      vpc-endpoint-service | vpc-peering-connection | vpn-connection | vpn-gateway
            cmd=( ec2 describe-tags )
            filter=(
                "Name=resource-type,Values=${type:-${resource%.tags}}"
                "Name=resource-id,Values=${1:?resource-id}"
              )
            shift

            # select specified tags
            [ $# -gt 0 ] && filter+=( Name=key,Values=`join_string -zd ',' "$@"` )

            field='Tags'
            post=( __JQ -s 'from_entries' )
            ;;
#    route)
#    subnet)
    *target-group?(s))
        #FIXME use filter to pick items
            __AWS elbv2 describe-target-groups |
                __JQ --arg tg ${1:?target_group_name} '.TargetGroups[] | select(.TargetGroupName == $tg)'
            ;;

#   ebs|volume) describe-volume
    *volume-attachment)
            __AWS ec2 describe-volumes --volume-ids ${1:?volume_id} |
                __JQ '.Volumes[].Attachments[0]'
            ;;

    *volume-status)
            # ok, creating, ?
            __AWS ec2 describe-volume-status --volume-ids ${1:?volume_id} |
                __JQR '.VolumeStatuses[].VolumeStatus.Status //empty'
            ;;

    vpc?(s)) cmd=( ec2 describe-vpcs )
            [ -n "$1" ] && filter=( Name=vpc-id,Values=$(join_string ',' "$@") )
            field='Vpcs'
            ;;

    vpc-endpoint-service?(s))
            __AWS ec2 describe-vpc-endpoint-services \
                --service-name "com.amazonaws.${AWS_DEFAULT_REGION:-${__aws_defaults[region]}}.${1:?service}" |
                __JQ '.ServiceDetails[]'
            ;;

    vpc-endpoint?(s))
            __AWS ec2 describe-vpc-endpoints --vpc-endpoint-ids ${1:?endpoint_id} |
                __JQ '.VpcEndpoints[]'
            ;;

#    target-group)
#    elb|lb|load-blancer)
#    security-group)
#   launch-config)
#    ssm.parameter)
    *)      log.error "unsupported keyword ($resource)"; return 2
  esac

  # quick hack to bypass general case
#  [ -n "$legacy" ] && return

  [ -n "$filter" ] && cmd+=( '--filters' "${filter[@]}" )

  if [ -n "$post" ]; then
    __AWS "${cmd[@]}" | __JQ --arg field "${field:?}" '.[$field][]' | "${post[@]}"
  elif [ -n "$field" ]; then
    __AWS "${cmd[@]}" | __JQ --arg field "${field:?}" '.[$field][]'
  else
    log.notice "FIXME legacy entry ($resource)"; return 0
  fi
}


# similar to aws.describe() but intended to return singleton values safe for shell consumption, not long-winded JSON
function aws.get() {
  local keyword
  local -a filter=()
  #TODO format with 'a' or 'A' like aws.list and use getopts()

  keyword=${1:?item}; shift

  case "$keyword" in
    *.tag)  aws.describe "$keyword" ${1:?resource-id} "${2:?key}" |
                __JQR --arg key "$2" '.[$key]'
            ;;

#    *.tags) aws.describe "$keyword" "${1:?resouce-id}" "${@:2}" |
#             format with 'a' or 'A' like aws.list
#            ;;

    ssm.parameter)
            #TODO? join_string('/', "$prefix", ${@:?parameter-key})
            __AWS ssm get-parameter --name "${1:?parameter}" --with-decryption |
                __JQR '.Parameter.Value'
            ;;

    ssm.parameters)
            # key and value emitted on successive lines to simplify whitespace handling.
            # consume via loop since direct eval() of ^/.+ which is not legal in SHELL:
            #   while read -r key; do read -r value; ... done
            __AWS ssm get-parameters --names "${@:?parameter}" --with-decryption |
                __JQR '.Parameters[] | "\(.Name)", "\(.Value)"'
#FIXME return associative array so no caller parsing, use format from above
#                __JQR '.Parameters[] | "[\(.Name)]=\'\(.Value)\'"'
            ;;

    sts.account)
            __AWS sts get-caller-identity | __JQR '.Account'
            ;;

    *)      log.error "unsupported keyword ($keyword)"
            return 2
  esac
}

    #target-group.instances - all EC2 instances assigned to a TG
    #lb.instances - ditto for old LB style, detect if new (has TG) and iterate
    #lb.membership - return all LB of which instance is a target. if LB is new (ie. has member TG) iterate thru them
    #tg.membership - for new style

#aws elb describe-load-balancers | __JQR '.LoadBalancerDescriptions[] | select(.Instances[].InstanceId == "<YOUR-INSTANCE-ID>") | . LoadBalancerName '
# or
#aws elb describe-load-balancers --query "LoadBalancerDescriptions[?Instances[?InstanceId=='${instanceId}']].LoadBalancerName"
# but does NOT work with elbv2!!! have to loop thru all known target-groups
#
#    for tg in `aws elbv2 describe-target-groups --query "TargetGroups[?VpcId=='${vpc_id}'].TargetGroupArn" | __JQR '.[]'`; do
#              __AWS elbv2 describe-target-health --target-group-arn "$tg" --query "TargetHealthDescriptions[?Target.Id=='${instance_id}']" | __JQ
#    '.[]' >/dev/null && echo $tg
#
#      #alt: __JQR --arg instance "${instance_id:?}" 'select(.TargetHealthDescriptions[].Target.Id == $instance)'
#      done


# Abstract out various incompatible syntax for setting Tags
function aws.format_tag() {
  local delim format json=0
  local -A __printf=(
      [KV]=		# $key=$value
	  [jKV]=	# compose JSON via eg. jq --null-input --arg K "$k" --arg V "$v" '{ "Key": $k, "Value": $v}'
	  [KkVv]=	# Key=$key,Value=$value
	  [jKkVv]=
    )

#TODO specify input_format?
  local OPTIND opt
  while getopts ':f:h' opt; do
    case "${opt}" in
      sqs)  format=${__printf[XXX]}; delim=X
			cmd=( 'XXX' )
			;;
      ddb|dynamodb)
	        format=${__printf[XXX]}; delim=X
			;;
	  ec2)  format=${__printf[KkVv]}; delim=' '
			cmd=( '--tags' )
			;;
      :)    log.error "missing argument (-$OPTARG)"
			return 2
			;;
      \?|*) log.error "unsupported (-${OPTARG:-opt})" ;&
      h)    >&2 echo "Usage: $FUNCNAME ... TODO"
            return 2
    esac
  done
  shift $((OPTIND - 1))
  
  #TODO if first char of $1 is '{' use JQ

  while (( $# )); do
	[ -n "$1" ] || { shift; continue; }
			  
	if __JQ '.' <<< "$1"		  kv=( `sed 's/[=,]/\n/g' <<< "$1"` )
			  if [[ ${kv[0]:-X} =~ [kK]ey$ && ${kv[2]:-X} =~ [vV]alue$ ]]; then
			    args+=( "Key=${kv[1]},Value=${kv[3]}" )
			  else
			  [ ${#kv[@]} -eq 2 ]; then
				args+=( "Key=${kv[0]},Value=${kv[1]}"
			  else
			    log.error "invalid format ($1)"; return 2
			  fi
			done


}

# Invoked as single-ton - use external loop, though some items allow cheating via comma-delimited
function aws.set() {
  local keyword resource
  local -a cmd args kv

  keyword=${1:?item}; shift

  case "$keyword" in

#    sqs.tag)
#    dynamodb.tag)
#    ec2.tag)
#    *.tag)

    # ref: https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/create-tags.html
    ec2.tag?(s))
            cmd=( ec2 create-tags )
            local item=${1:?resource}
            #TODO escape special chars like '[],' nee Key=\"[Group]\",Value=test or 'Key="[Group]",Value=test'
			while (( $# )); do
			  [ -n "$1" ] || { shift; continue; }
			  
			  kv=( `sed 's/[=,]/\n/g' <<< "$1"` )
			  if [[ ${kv[0]:-X} =~ [kK]ey$ && ${kv[2]:-X} =~ [vV]alue$ ]]; then
			    args+=( "Key=${kv[1]},Value=${kv[3]}" )
			  else
			  [ ${#kv[@]} -eq 2 ]; then
				args+=( "Key=${kv[0]},Value=${kv[1]}"
			  else
			    log.error "invalid format ($1)"; return 2
			  fi
			done
            __AWS "${cmd[@]}" --resources "${item//,/ }" --tags "${args[@]:-$@}"
            ;;

    ssm.parameter)
            #[ "$1" = '-s' ] && { secure=1; shift; }
            #or inspect ${1%%:*} where member of String, List|StringList, Secure|SecureString
            #_type=String
            [ -n "$DELETE" ] &&
                cmd=( delete-parameter ) ||
                cmd=( put-parameter '--type' ${_type:-String} '--overwrite' '--value' "$2" )

            __AWS ssm "${cmd[@]}" --name "${1:?key}"
            ;;

    *)      log.error "unsupported keyword ($keyword)"
            return 2
  esac
}


function asg.suspend() {
  local asg=${1:?ASG name}; shift

  __AWS autoscaling enter-standby \
      --auto-scaling-group-name "$asg" \
      --should-decrement-desired-capacity \
      ${1:+ --instance-ids "$@"}
}


function asg.resume() {
  local asg=${1:?ASG name}; shift

  __AWS autoscaling exit-standby \
      --auto-scaling-group-name "$asg" \
      ${1:+ --instance-ids "$@"}
}


function asg.scale-zero() {
  min=0 desired=0 asg.set-capacity "$@"
}


function asg.set-capacity() {
  local -i min desired max

  [ -n "${min}${desired}${max}" ] || return 2
  asg=${1:?ASG name}; shift

  __AWS autoscaling update-auto-scaling-group \
      --auto-scaling-group-name "$asg" \
      ${min:+ --min-size $min} \
      ${desired:+ --desired-capacity $desired} \
      ${max:+ --max-size $max}
}


# wrapper around aws.describe emits 2 columns: <resource id>   ["Tag:Name"] for
# human-friendly display of items and dynamic array assembly
# TODO? '-A' for assoc array format, '-a' for normal array and omits 2nd column
function aws.list() {
  local -i sort name
  local OPTIND opt format

  while getopts 'aA' opt; do
    case "$opt" in
      a)    format='array' ;;
      A)    format='hash' ;;

      :)    log.error "missing argument (-$OPTARG)"; return 2 ;;
      \?)   log.error "unsupported (-$OPTARG)" ;&
      h)    >&2 echo "Usage: $FUNCNAME ... TODO"
            return 2
    esac
  done
  shift $((OPTIND - 1))

  keyword=${1:?item}; shift

  case "$keyword" in
    vpc?(s)) field='VpcId' ;;

    *)      log.error "unsupported keyword ($keyword)"; return 2
  esac

#TODO if name=0  cmd[1]=__JQ --arg field "$field" '.[$field], ""'
#TODO if sort=1  can JQ sort?

  # shell-friendly output
  case "${format:-json}" in
    # 2 lines per entry. readarray -t VAR < <(aws.list ...)
    a|array) aws.describe "$keyword" "$@" |
                __JQR --arg field "$field" '.[$field], (.Tags | from_entries | .Name // "")'
            ;;

    # format? if TAB, 'while IFS=$'\t' read -t key val
    # otherwise, read key && read val
    A|hash) aws.describe "$keyword" "$@" |
                __JQR --arg field "$field" '".[$field]=\(.Tags | from_entries | .Name // "")"'
            ;;

    json)   aws.describe "$keyword" "$@" |
                __JQ --arg field "$field" '{ (.[$field]): (.Tags | from_entries | .Name // "") }' |
                __JQ -s 'add'
            ;;
    # not reached
    *)      log.error "unsupported format ($opt)"; return 2
  esac

  #TODO generic execution - $cmd1 | $cmd2 | $cmd3
}


#function ec2.connect takes after 18f script that probes for region, VPC, and then instance

#function s3.restore
#aws s3 ls s3://<bucket_name> | awk '{print $4}' | xargs -L 1 aws s3api restore-object --restore-request Days=<days> --bucket <bucket_name> --key
# or better
# s3cmd restore --recursive s3://mybucketname/

# simple example of qlgrep but need to find my original from AWS
# szcat <file> | grep '^Key=' | sed -e 's|^\([^/]\+/[^/]\+\).*|\1|' | sort | uniq -dc


# vim: expandtab:ts=8:sw=4
